{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a12c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello, World!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b58769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set working directory to project root so relative paths resolve consistently\n",
    "os.chdir(r\"D:\\Sai Teja Honours\\GenmedAssist\")\n",
    "print('CWD set to', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b80e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f628943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c45f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def load_pdf_files(data):\n",
    "    pdf_files = Path(data).glob(\"*.pdf\")\n",
    "    documents = []\n",
    "    for pdf in pdf_files:\n",
    "        loader = PyPDFLoader(str(pdf))\n",
    "        documents.extend(loader.load())\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_files(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d41b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433da66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_to_minimal_docs(documents: List[Document]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Given a list of Document objects, return a new list of Document objects\n",
    "    containing only the original page_content and a metadata dict with 'source'.\n",
    "    \"\"\"\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in documents:\n",
    "        src = doc.metadata.get(\"source\") if isinstance(doc.metadata, dict) else None\n",
    "        minimal_docs.append(Document(page_content=doc.page_content, metadata={\"source\": src}))\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f19d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_docs = filter_to_minimal_docs(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaeb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import re\n",
    "\n",
    "# --- Clean Function ---\n",
    "def clean_text(text):\n",
    "    \"\"\"Remove unwanted characters and normalize spacing.\"\"\"\n",
    "    text = text.replace('\\n', ' ')               # Replace newlines with spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()     # Remove multiple spaces\n",
    "    return text\n",
    "\n",
    "# --- Split + Clean Function ---\n",
    "def text_split(minimal_docs):\n",
    "    \"\"\"Clean and split documents into smaller chunks.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "    )\n",
    "\n",
    "    cleaned_docs = []\n",
    "    for doc in minimal_docs:\n",
    "        doc.page_content = clean_text(doc.page_content)\n",
    "        cleaned_docs.append(doc)\n",
    "\n",
    "    # Split the cleaned docs\n",
    "    texts_chunk = text_splitter.split_documents(cleaned_docs)\n",
    "\n",
    "    # Clean each chunk again (safety pass)\n",
    "    for chunk in texts_chunk:\n",
    "        chunk.page_content = clean_text(chunk.page_content)\n",
    "\n",
    "    # Print all cleaned chunks before embedding\n",
    "    print(\"\\nðŸ“„ --- Cleaned Text Chunks ---\\n\")\n",
    "    for i, chunk in enumerate(texts_chunk, 1):\n",
    "        print(f\"Chunk {i}:\")\n",
    "        print(chunk.page_content)\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    return texts_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ffc3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_chunk = text_split(minimal_docs)\n",
    "print(f\"Number of chunks: {len(texts_chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77016dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab366f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    \"\"\"\n",
    "    Download and return the HuggingFace embeddings model.\n",
    "    \"\"\"\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding = download_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b413439",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = embedding.embed_query(\"Hello world\")\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe7c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Vector length:\", len(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9197c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print( \"Vector length:\", len(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758273c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751d42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pinecone import Pinecone \n",
    "pinecone_api_key = PINECONE_API_KEY\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcebf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd5a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "index_name = \"genmedassist\"\n",
    "\n",
    "# --- Step 1: Create the index if it doesn't exist ---\n",
    "if not pc.has_index(index_name):\n",
    "    print(f\"Creating new index: {index_name}\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,     # must match your embedding model output\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists. âœ…\")\n",
    "\n",
    "# --- Step 2: Connect to the existing index ---\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# --- Step 3: Load or upload documents safely ---\n",
    "\n",
    "LOAD_NEW_DATA = False  # <-- change to True only when adding new docs\n",
    "\n",
    "if LOAD_NEW_DATA:\n",
    "    # â¬‡ï¸ This runs only when you want to embed new files\n",
    "    docsearch = PineconeVectorStore.from_documents(\n",
    "        documents=texts_chunk,\n",
    "        embedding=embedding,\n",
    "        index_name=index_name,\n",
    "    )\n",
    "    print(\"âœ… Uploaded new documents to Pinecone.\")\n",
    "else:\n",
    "    # â¬‡ï¸ Safe mode: just connect to existing data\n",
    "    docsearch = PineconeVectorStore.from_existing_index(\n",
    "        index_name=index_name,\n",
    "        embedding=embedding,\n",
    "    )\n",
    "    print(\"ðŸ”’ Loaded existing Pinecone index (no upload).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e10bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ques = retriever.invoke(\"what are white blood cells ?\")\n",
    "ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae784a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dbaf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f54d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "     \"You are a Medical assistant for diagnostic tasks that gives concise and accurate information. \"\n",
    "        \"You will give diagnoses based on the context provided. For patients, use simple terms. \"\n",
    "        \"For doctors, provide technical terms using ICD-10 codes. \"\n",
    "        \"Use the following pieces of retrieved context to answer the question. \"\n",
    "        \"If you don't know the answer, say that you don't know. \"\n",
    "        \"Use three sentences maximum and keep the answer concise.\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c5db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(chatModel, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c408b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is Acne? symptomps and treatment options?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb45332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07623e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50a164f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f9a489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c6f263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c6fd03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e49214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a64c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad4c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963bd599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7e2387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e937f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd084d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d10f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenmedAssist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
